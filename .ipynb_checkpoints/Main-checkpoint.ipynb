{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c9c5708-5e68-41ed-b710-bcf3622b8b7a",
   "metadata": {},
   "source": [
    "## Importing Libraries\n",
    "To download all the required libraries, run the following pip command, also you can find a requirement.txt file for the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97b52aa0-4ed6-41a1-9823-195f3aaf5019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas scikit-learn tensorflow transformers matplotlib numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeba5fa-8411-4c25-9c4a-4272503818e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "# from tensorflow.keras.models import load_model\n",
    "# from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import os\n",
    "# Data handling and preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# TensorFlow and Keras for building models\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# PyTorch and Transformers for BERT\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e76ce5e-a389-4383-8c5e-1c5db2103653",
   "metadata": {},
   "source": [
    "## Exploration and Preprocesssing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb43b22e-9762-4a14-acf2-db4f41a6ef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import pandas as pd\n",
    "dataset_path = './Problem_Dataset.csv'\n",
    "data = pd.read_csv(dataset_path)\n",
    "\n",
    "# Distribution of 'Type' column\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.countplot(x='Type', data=data)\n",
    "plt.title('Distribution of Type')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3ec40e-a546-4269-8a9e-45f1a9d80c8e",
   "metadata": {},
   "source": [
    "#### Each type (B3, B4, A3, B1, B2, A1, A2) has roughly the same count. This indicates that the dataset is balanced in terms of the number of samples for each type. there is no class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982f57aa-dda1-4fa9-9119-a4fe7d0832e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text length analysis\n",
    "data['text_length'] = data['Obs'].apply(len)\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.histplot(data['text_length'], bins=20, kde=True)\n",
    "plt.title('Distribution of Text Length in Obs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5598d498-1dbf-47bd-83e4-b207529942a9",
   "metadata": {},
   "source": [
    "#### This is a histogram with a kernel density estimate(KDE) line which shows bell shaped curve which shows a peak around 120 whixh tells that most of the samples are 120 charachters long, this information can be used to define sequence length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac2c1e8-73bb-4448-aacc-d7a53389862d",
   "metadata": {},
   "source": [
    "#### The Dataset is well balance as it has equal number of positive instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615be6ae-eda9-4b3b-915d-037f628e184b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "MAX_VOCAB_SIZE = 10000\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "# Preprocessing the data\n",
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    Preprocessing the Input Data, here the function helps to tokenize the text,\n",
    "    helps in padding our sentences sequence and splitrting it in Training sets and Validation Sets\n",
    "\n",
    "    Parameters:\n",
    "    df : The function takes df as argument on the preprocessing is meant to be done\n",
    "\n",
    "    Returns:\n",
    "    X_train : Training data which consists of padded sequence.\n",
    "    X_val : Validation data which consists of padded sequence.\n",
    "    y_train : Training labels with binary colums A1 to B4\n",
    "    y_val : Validation labels with binary colums A1 to B4\n",
    "    tokenizer : This is fitted tokenizer which will transfor the data as passed.\n",
    "    \"\"\"\n",
    "    # During tokenization we need to limit number of unique words to be considered\n",
    "    # initializing a tokenizer having maximum vocabulary size (which is defined globally)\n",
    "    tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
    "    \n",
    "    # Fitting it on Obs column of the dataset\n",
    "    tokenizer.fit_on_texts(df['Obs'])\n",
    "    # We will need to convert the text data into integers\n",
    "    # here this method will assign an integer value\n",
    "    sequences = tokenizer.texts_to_sequences(df['Obs'])\n",
    "    \n",
    "    # Pad sequences to ensure uniform input length\n",
    "    X = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    \n",
    "    # Extract labels\n",
    "    labels = df[['A1', 'A2', 'A3', 'B1', 'B2', 'B3', 'B4']]\n",
    "    \n",
    "    # Split into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
    "    \n",
    "    return X_train, X_val, y_train, y_val, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c7b491-fcd1-471b-99b7-b3cc3466a3dc",
   "metadata": {},
   "source": [
    "## Building a LSTM based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8cef82-ed24-4855-b71c-2f0593e8b5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_length, vocab_size, num_labels):\n",
    "    \"\"\"\n",
    "    This function is for building and compiling LSTM architecture based Model.\n",
    "\n",
    "    Parameters:\n",
    "    input_length : It defines the length of input sequence, number of words in each input\n",
    "    vocab_size : It difines the number of unique words in data.\n",
    "    num_labels (int): The number of labels or classes for the multi-label classification task.\n",
    "    \n",
    "    Return:\n",
    "    model : returns a sequential model which can be further used for training.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initializing a sequential model\n",
    "    model = Sequential()\n",
    "    # Here embedding layer is used to convert each word into dense vector of fixed size\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=EMBEDDING_DIM, input_length=input_length))\n",
    "    # Using a LSTM model, here 128 refers to 128 neurons or LSTM units\n",
    "    # Adding return_sequence as true to return full sequence as outputs for the following LSTM layer\n",
    "    model.add(LSTM(128, return_sequences=True))\n",
    "    # To avoid overfitting, adding a dropout layer and dropping 20% of neurons \n",
    "    model.add(Dropout(0.2))\n",
    "    # Here by default the input_sequence is false as only last output in the sequence is needed\n",
    "    model.add(LSTM(64))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(num_labels, activation='sigmoid'))\n",
    "    # Using binary crossentropy loss function and adam optimizer\n",
    "    # To update weights based on the loss.\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02662786-88a8-4497-8ab7-60026a29db9e",
   "metadata": {},
   "source": [
    "## Binary Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582f5d9e-151c-43bd-a275-f48f472a68eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models for each binary label\n",
    "def train_binary_models(X_train, y_train, X_val, y_val, input_length, vocab_size,model_dir):\n",
    "    \"\"\"\n",
    "    Trains binary classification models for each label in the dataset and saves them to disk.\n",
    "\n",
    "    Parameters:\n",
    "    X_train (np.ndarray): Training data consisting of padded sequences.\n",
    "    y_train (pd.DataFrame): Training labels, where each column represents a binary label.\n",
    "    X_val (np.ndarray): Validation data consisting of padded sequences.\n",
    "    y_val (pd.DataFrame): Validation labels corresponding to binary columns in y_train.\n",
    "    input_length (int): The length of the input sequences (number of words per sequence).\n",
    "    vocab_size (int): The size of the vocabulary (number of unique words).\n",
    "    model_dir (str): The directory where the trained models will be saved.\n",
    "\n",
    "    Returns:\n",
    "    models (dict): A dictionary where keys are label names and values are the corresponding trained models.\n",
    "    \"\"\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    # Initializing an empty dictionary to save trained models for each label\n",
    "    models = {}\n",
    "    # Looping through each label in training data\n",
    "    for label in y_train.columns:\n",
    "        print(f\"Training model for {label}...\")\n",
    "        model = build_model(input_length, vocab_size,1)\n",
    "        # Train for 5 epochs\n",
    "        # Stop training early if the validation loss doesn't improve for 2 consecutive epochs.\n",
    "        model.fit(X_train, y_train[label], epochs=5, validation_data=(X_val, y_val[label]), \n",
    "                  callbacks=[EarlyStopping(patience=2)], batch_size=32)\n",
    "        # # Save the trained model to disk in the specified directory.\n",
    "        model.save(os.path.join(model_dir, f\"{label}_model.h5\"))  \n",
    "        # Store the trained model in the `models` dictionary, using the label as the key.\n",
    "        models[label] = model  \n",
    "    return models\n",
    "\n",
    "# Function to load models from the directory\n",
    "def load_models(model_dir, labels):\n",
    "    \"\"\"\n",
    "    Loads pre-trained binary classification models from disk.\n",
    "\n",
    "    Parameters:\n",
    "    model_dir (str): The directory where the trained models are stored.\n",
    "    labels (list of str): A list of label names corresponding to the models to be loaded.\n",
    "\n",
    "    Returns:\n",
    "    models (dict): A dictionary where keys are label names and values are the corresponding loaded models.\n",
    "    \"\"\"\n",
    "    models = {}\n",
    "    for label in labels:\n",
    "        model_path = os.path.join(model_dir, f\"{label}_model.h5\")\n",
    "        models[label] = load_model(model_path)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbea19dc-2c8f-4c88-a909-eb50496dcf2f",
   "metadata": {},
   "source": [
    "## Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d503b7-fdc8-4af1-ac2f-b89bc6a23cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ensemble(models, X):\n",
    "    \"\"\"\n",
    "    Generates ensemble predictions from multiple binary classification models.\n",
    "\n",
    "    Parameters:\n",
    "    models (dict): A dictionary where keys are label names and values are trained models.\n",
    "    X (np.ndarray): The input data on which predictions will be made.\n",
    "\n",
    "    Returns:\n",
    "    final_predictions (np.ndarray): A 2D array with binary predictions (0 or 1) for each label.\n",
    "    \"\"\"\n",
    "    ensemble_predictions = np.zeros((X.shape[0], len(models))) \n",
    "    # Loop through each model and its corresponding label.\n",
    "    for i, (label, model) in enumerate(models.items()):\n",
    "        # Make predictions using the model for the current label.\n",
    "        # Also using squeeze() to make sure predictions are 1D\n",
    "        preds = model.predict(X).squeeze()  \n",
    "        ensemble_predictions[:, i] = preds  \n",
    "    # Convert the ensemble predictions to binary (0 or 1) based on a threshold of 0.5.\n",
    "    final_predictions = (ensemble_predictions >= 0.5).astype(int)\n",
    "    \n",
    "    return final_predictions\n",
    "\n",
    "# Calculate metrics for each label\n",
    "def calculate_metrics(final_predictions, y_true, labels):\n",
    "    \"\"\"\n",
    "    Calculates precision, recall, and F1-score for each label.\n",
    "\n",
    "    Parameters:\n",
    "    final_predictions (np.ndarray): The predicted binary labels.\n",
    "    y_true (pd.DataFrame): The true labels corresponding to each label.\n",
    "    labels (list of str): The list of label names.\n",
    "\n",
    "    Returns:\n",
    "    metrics (dict): A dictionary where each label has a sub-dictionary with precision, recall, and F1-score.\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    # Loop through each label and its corresponding index.\n",
    "    for i, label in enumerate(labels):\n",
    "        y_pred = final_predictions[:, i]\n",
    "        y_actual = y_true[label].values\n",
    "        precision = precision_score(y_actual, y_pred)\n",
    "        recall = recall_score(y_actual, y_pred)\n",
    "        f1 = f1_score(y_actual, y_pred)\n",
    "        metrics[label] = {\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1\n",
    "        }\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def save_metrics(metrics, file_path):\n",
    "    \"\"\"\n",
    "    Save the provided metrics dictionary to a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    - metrics (dict): A dictionary where each key is a label, and each value is another dictionary\n",
    "      containing metric names and their corresponding values.\n",
    "    \n",
    "    - file_path (str): The path to the CSV file where the DataFrame will be saved.\n",
    "      Example: \"output/metrics.csv\"\n",
    "\n",
    "    Returns:\n",
    "    - None: The function does not return any value. It writes the metrics data to a CSV file specified by `file_path`.\n",
    "    \"\"\"\n",
    "    # Prepare data for DataFrame\n",
    "    data = []\n",
    "    for label, metric in metrics.items():\n",
    "        for metric_name, value in metric.items():\n",
    "            data.append([label, metric_name, value])\n",
    "    \n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame(data, columns=[\"Label\", \"Metric\", \"Value\"])\n",
    "    \n",
    "    # Save DataFrame to CSV\n",
    "    df.to_csv(file_path, index=False)\n",
    "\n",
    "# Save predictions to a CSV file\n",
    "def save_predictions(predictions, original_data, labels, file_path):\n",
    "    \"\"\"\n",
    "    Saves the ensemble predictions to a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    predictions (np.ndarray): The binary predictions generated by the ensemble.\n",
    "    original_data (pd.DataFrame): The original data containing columns like 'sID' and 'Obs'.\n",
    "    labels (list of str): The list of label names corresponding to the predictions.\n",
    "    file_path (str): The file path where the predictions will be saved.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    pred_df = pd.DataFrame(predictions, columns=labels)\n",
    "    results_df = pd.concat([original_data[['sID', 'Obs']], pred_df], axis=1)\n",
    "    results_df.to_csv(file_path, index=False)\n",
    "\n",
    "\n",
    "# Main function to load models, make predictions, and evaluate\n",
    "def main(model_dir, X_val, y_val, labels, metrics_output_file, predictions_output_file):\n",
    "    \"\"\"\n",
    "    Main function to load models, make predictions, evaluate, and save results.\n",
    "\n",
    "    Parameters:\n",
    "    model_dir (str): The directory where the trained models are stored.\n",
    "    X_val (np.ndarray): The validation data on which predictions will be made.\n",
    "    y_val (pd.DataFrame): The true validation labels.\n",
    "    labels (list of str): The list of label names.\n",
    "    metrics_output_file (str): The file path to save the evaluation metrics.\n",
    "    predictions_output_file (str): The file path to save the predictions.\n",
    "\n",
    "    Returns:\n",
    "    final_predictions (np.ndarray): The binary predictions generated by the ensemble.\n",
    "    metrics (dict): The calculated precision, recall, and F1-score for each label.\n",
    "    \"\"\"\n",
    "    # Load the models\n",
    "    models = load_models(model_dir, labels)\n",
    "    \n",
    "    # Predict using ensemble\n",
    "    final_predictions = predict_ensemble(models, X_val)\n",
    "    \n",
    "    # Calculate precision, recall, and F1-score\n",
    "    metrics = calculate_metrics(final_predictions, y_val, labels)\n",
    "    \n",
    "    # Save metrics to a file\n",
    "    save_metrics(metrics, metrics_output_file)\n",
    "    \n",
    "    # Save predictions to a file\n",
    "    save_predictions(final_predictions, df, labels, predictions_output_file)\n",
    "    \n",
    "    return final_predictions, metrics\n",
    "\n",
    "# Define labels\n",
    "labels = ['A1', 'A2', 'A3', 'B1', 'B2', 'B3', 'B4']\n",
    "\n",
    "dataset_path = './Problem_Dataset.csv'\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Preprocess the data\n",
    "X_train, X_val, y_train, y_val, tokenizer = preprocess_data(df)\n",
    "\n",
    "# Directory where models should be saved\n",
    "model_dir = './Ensemble/Models'\n",
    "\n",
    "# Train binary classification models\n",
    "binary_models = train_binary_models(X_train, y_train, X_val, y_val, X_train.shape[1], len(tokenizer.word_index) + 1, model_dir)\n",
    "\n",
    "# Output files to save metrics and predictions\n",
    "metrics_output_file = './Ensemble/metrics.csv'\n",
    "predictions_output_file = './Ensemble/ensemble_predictions.csv'\n",
    "\n",
    "# Evaluate the ensemble models and save predictions\n",
    "final_predictions, ensemble_metrics = main(model_dir, X_val, y_val, labels, metrics_output_file, predictions_output_file)\n",
    "\n",
    "# Display metrics\n",
    "for label, metric in ensemble_metrics.items():\n",
    "    print(f\"{label} metrics:\")\n",
    "    print(f\"  Precision: {metric['precision']:.4f}\")\n",
    "    print(f\"  Recall:    {metric['recall']:.4f}\")\n",
    "    print(f\"  F1-Score:  {metric['f1_score']:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04811277-3310-42d1-a126-c34abc5c4aae",
   "metadata": {},
   "source": [
    "## Multi-Label Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffe25d8-8f4e-49db-91f3-229f0a58838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_multi_label_model(input_length, vocab_size, num_labels):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=EMBEDDING_DIM, input_length=input_length))\n",
    "    model.add(LSTM(128, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(64))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(num_labels, activation='sigmoid'))  # 7 output units for 7 labels (A1 to B4)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_multi_label_model(X_train, y_train, X_val, y_val, input_length, vocab_size, MultiModel_dir):\n",
    "    \"\"\"\n",
    "    Train a multi-label classification model using the provided training and validation data.\n",
    "\n",
    "    Parameters:\n",
    "    X_train (numpy.ndarray): The training input data,  array of sequences.\n",
    "    y_train (numpy.ndarray): The training labels, array where each row corresponds to a multi-label binary vector.\n",
    "    X_val (numpy.ndarray): The validation input data, used to evaluate the model during training.\n",
    "    y_val (numpy.ndarray): The validation labels, used to assess the model's performance during training.\n",
    "    input_length (int): The length of the input sequences, defining the number of words in each input sequence.\n",
    "    vocab_size (int): The size of the vocabulary, i.e., the number of unique tokens or words in the input data.\n",
    "    MultiModel_dir (str): The directory path where the trained model will be saved.\n",
    "\n",
    "    Returns:\n",
    "    model : The trained Sequential model.\n",
    "    \"\"\"\n",
    "    os.makedirs(MultiModel_dir, exist_ok=True)\n",
    "    num_labels = y_train.shape[1]\n",
    "    # Build the model\n",
    "    model = build_multi_label_model(input_length, vocab_size, num_labels)\n",
    "    \n",
    "    print(\"Training multi-label model...\")\n",
    "    model.fit(X_train, y_train, epochs=15, validation_data=(X_val, y_val), \n",
    "              callbacks=[EarlyStopping(patience=2)], batch_size=32, verbose =1)\n",
    "    # Save the trained model to the specified directory\n",
    "    model.save(os.path.join(MultiModel_dir, \"multi_label_model.h5\")) \n",
    "    return model\n",
    "\n",
    "def predict_multi_label_model(model, X):\n",
    "    \"\"\"\n",
    "    Generate binary predictions from a multi-label classification model.\n",
    "\n",
    "    Parameters:\n",
    "    model : The trained model used for making predictions.\n",
    "    X (numpy.ndarray): The input data for which predictions are to be made. This is a 2D array of sequences.\n",
    "\n",
    "    Returns:\n",
    "    final_predictions (numpy.ndarray): A 2D array of binary predictions (0 or 1) for each label.\n",
    "    \"\"\"\n",
    "    # Predict probabilities for each label\n",
    "    predictions = model.predict(X)\n",
    "    # Convert probabilities to binary predictions\n",
    "    final_predictions = (predictions >= 0.4).astype(int)\n",
    "    return final_predictions\n",
    "\n",
    "def calculate_multi_label_metrics(final_predictions, y_true):\n",
    "    \"\"\"\n",
    "    Calculate precision, recall, and F1 score for each label in a multi-label classification task.\n",
    "\n",
    "    Parameters:\n",
    "    final_predictions (numpy.ndarray): The binary predictions generated by the model, a 2D array where each column corresponds to a label.\n",
    "    \n",
    "    y_true (pandas.DataFrame): The true labels for the dataset, where each column represents a label.\n",
    "\n",
    "    Returns:\n",
    "    metrics (dict): A dictionary containing precision, recall, and F1 score for each label.\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    for i, label in enumerate(y_true.columns):\n",
    "        y_pred = final_predictions[:, i]\n",
    "        y_actual = y_true[label].values\n",
    "        precision = precision_score(y_actual, y_pred)\n",
    "        recall = recall_score(y_actual, y_pred)\n",
    "        f1 = f1_score(y_actual, y_pred)\n",
    "        metrics[label] = {\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1\n",
    "        }\n",
    "    return metrics\n",
    "\n",
    "def save_multi_label_metrics(metrics, file_path):\n",
    "    \"\"\"\n",
    "    Save the provided metrics dictionary to a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    - metrics (dict): A dictionary where each key is a label, and each value is another dictionary\n",
    "      containing metric names and their corresponding values.\n",
    "    \n",
    "    - file_path (str): The path to the CSV file where the DataFrame will be saved.\n",
    "      Example: \"output/metrics.csv\"\n",
    "\n",
    "    Returns:\n",
    "    - None: The function does not return any value. It writes the metrics data to a CSV file specified by `file_path`.\n",
    "    \"\"\"\n",
    "    # Prepare data for DataFrame\n",
    "    data = []\n",
    "    for label, metric in metrics.items():\n",
    "        for metric_name, value in metric.items():\n",
    "            data.append([label, metric_name, value])\n",
    "    \n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame(data, columns=[\"Label\", \"Metric\", \"Value\"])\n",
    "    \n",
    "    # Save DataFrame to CSV\n",
    "    df.to_csv(file_path, index=False)\n",
    "\n",
    "def save_multi_label_predictions(predictions, original_data, labels, file_path):\n",
    "    \"\"\"\n",
    "    Save the multi-label predictions alongside original data to a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    predictions (numpy.ndarray): A 2D array of binary predictions (0 or 1) for each label.   \n",
    "    original_data (pandas.DataFrame): The original dataset, which includes columns such as 'sID' and 'Obs'.\n",
    "    labels (list): A list of label names corresponding to the columns in the predictions array.\n",
    "    file_path (str): The path to the CSV file where the predictions and original data will be saved.\n",
    "\n",
    "    Returns:\n",
    "    - None: This function does not return any value. It writes the predictions and original data to a CSV file.\n",
    "    \"\"\"\n",
    "    pred_df = pd.DataFrame(predictions, columns=labels)\n",
    "    results_df = pd.concat([original_data[['sID', 'Obs']], pred_df], axis=1)\n",
    "    results_df.to_csv(file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55b87d9-fa0a-40b7-851b-268bf5b68e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Multimain(model_dir, X_train, y_train, X_val, y_val, labels, metrics_output_file, predictions_output_file):\n",
    "    \"\"\"\n",
    "    Train a multi-label model, evaluate its performance, and save the results.\n",
    "\n",
    "    Parameters:\n",
    "    model_dir (str): Directory where the trained model will be saved.\n",
    "    X_train (numpy.ndarray): The training input data, a 2D array of sequences.\n",
    "    y_train (numpy.ndarray): The training labels, a 2D array where each row corresponds to a multi-label binary vector.\n",
    "    X_val (numpy.ndarray): The validation input data, used to evaluate the model during training.\n",
    "    y_val (numpy.ndarray): The validation labels, used to assess the model's performance during training.\n",
    "    labels (list): A list of label names corresponding to the columns in the predictions array.\n",
    "    metrics_output_file (str): The path to the file where the calculated metrics will be saved.\n",
    "    predictions_output_file (str): The path to the file where the predictions will be saved.\n",
    "\n",
    "    Returns:\n",
    "    final_predictions (numpy.ndarray): A 2D array of binary predictions (0 or 1) for each label.\n",
    "    metrics (dict): A dictionary containing precision, recall, and F1 score for each label.\n",
    "    \"\"\"\n",
    "    # Train the model\n",
    "    model = train_multi_label_model(X_train, y_train, X_val, y_val, X_train.shape[1], len(tokenizer.word_index) + 1, MultiModel_dir)\n",
    "    \n",
    "    # Predict using the trained model\n",
    "    final_predictions = predict_multi_label_model(model, X_val)\n",
    "    \n",
    "    # Calculate precision, recall, and F1-score\n",
    "    metrics = calculate_multi_label_metrics(final_predictions, y_val)\n",
    "    \n",
    "    # Save metrics to a file\n",
    "    save_multi_label_metrics(metrics, metrics_output_file)\n",
    "    \n",
    "    # Save predictions to a file\n",
    "    save_multi_label_predictions(final_predictions, df, labels, predictions_output_file)\n",
    "    \n",
    "    return final_predictions, metrics\n",
    "\n",
    "# Define labels\n",
    "labels = ['A1', 'A2', 'A3', 'B1', 'B2', 'B3', 'B4']\n",
    "\n",
    "dataset_path = './Problem_Dataset.csv'\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Preprocess the data\n",
    "X_train, X_val, y_train, y_val, tokenizer = preprocess_data(df)\n",
    "\n",
    "# Directory where models should be saved\n",
    "MultiModel_dir = './MultiModel/Models'\n",
    "\n",
    "# Output files to save metrics and predictions\n",
    "metrics_output_file = './MultiModel/metrics.csv'\n",
    "predictions_output_file = './MultiModel/multi_predictions.csv'\n",
    "\n",
    "# Evaluate the multi-label model and save predictions\n",
    "final_predictions, multi_label_metrics = Multimain(MultiModel_dir, X_train, y_train, X_val, y_val, labels, metrics_output_file, predictions_output_file)\n",
    "\n",
    "# Display metrics\n",
    "for label, metric in multi_label_metrics.items():\n",
    "    print(f\"{label} metrics:\")\n",
    "    print(f\"  Precision: {metric['precision']:.4f}\")\n",
    "    print(f\"  Recall:    {metric['recall']:.4f}\")\n",
    "    print(f\"  F1-Score:  {metric['f1_score']:.4f}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd096f2-e924-481d-bd88-6e7641a84266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "def plot_metrics_line_chart(file_path):\n",
    "    # Load the CSV into a DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Set up the plot size and style\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    \n",
    "    # Plot each label's metrics as a separate line\n",
    "    for label in df['Label'].unique():\n",
    "        label_data = df[df['Label'] == label]\n",
    "        plt.plot(label_data['Metric'], label_data['Value'], marker='o', label=label)\n",
    "    \n",
    "    # Add title and labels\n",
    "    plt.title('Metrics Comparison Across Labels', fontsize=16)\n",
    "    plt.xlabel('Metric', fontsize=14)\n",
    "    plt.ylabel('Value', fontsize=14)\n",
    "    \n",
    "    # Show legend\n",
    "    plt.legend(title='Label')\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Example usage\n",
    "file_path = \"Ensemble/metrics.csv\"  # Update this path to your actual CSV file path\n",
    "plot_metrics_line_chart(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b74aa4-9c93-4535-93c4-68682873ecac",
   "metadata": {},
   "source": [
    "## BERT Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf441c9-757f-4be5-86e5-4175f23f17c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch.utils.data import Dataset, DataLoader, random_split\n",
    "# from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "# from sklearn.preprocessing import MultiLabelBinarizer\n",
    "# from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "file_path = './Problem_Dataset.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Preprocessing\n",
    "sentences = df['Obs'].values\n",
    "labels = df[['A1', 'A2', 'A3', 'B1', 'B2', 'B3', 'B4']].values\n",
    "\n",
    "# Split data into training and validation sets\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(sentences, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c29e14-e476-44a9-bbb3-eed07d469883",
   "metadata": {},
   "source": [
    "#### Here, a custom dataset is to be made which inherits from torch.utils.data.Dataset, which is an abstract class that PyTorch uses to load data. By creating a custom dataset, we can ensure that data is structured and processed in a way that the model can work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1e0ac9-65e2-417b-bc19-238c102f945e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        # Initialize with texts, labels, tokenizer, and max_len parameters\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the total number of samples in the dataset\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # For a given index, retrieve the corresponding text and label\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Tokenize the text using the tokenizer provided\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False, # Not needed for classification\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True, # Returning Attention Mask\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        # Return the text, input_ids, attention_mask, and labels as a dictionary\n",
    "        return {\n",
    "            'text': text,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc74245-7539-479e-aaf3-f4307b70348d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the BERT tokenizer using the 'bert-base-uncased' model\n",
    "# The 'bert-base-uncased' tokenizer converts the input text into tokens compatible with the BERT model.\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "max_len = 128\n",
    "batch_size = 16\n",
    "\n",
    "# Create data loaders for training and validation\n",
    "train_dataset = CustomDataset(train_texts, train_labels, tokenizer, max_len)\n",
    "val_dataset = CustomDataset(val_texts, val_labels, tokenizer, max_len)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Load the BERT model for sequence classification\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=7)\n",
    "\n",
    "# Define the device: Use GPU if available, otherwise use CPU\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "model = model.to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
    "\n",
    "# Training loop\n",
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch + 1}/{epochs}, Loss: {avg_loss}')\n",
    "\n",
    "# Validation\n",
    "model.eval()\n",
    "val_predictions, val_true_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        val_predictions.append(logits)\n",
    "        val_true_labels.append(labels)\n",
    "\n",
    "# Convert predictions to binary labels\n",
    "predicted_labels = (torch.sigmoid(torch.cat(val_predictions)) > 0.5).int()\n",
    "true_labels = torch.cat(val_true_labels).int()\n",
    "\n",
    "# Calculate accuracy, precision, recall, f1-score on the validation set\n",
    "accuracy = accuracy_score(true_labels.cpu(), predicted_labels.cpu())\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(true_labels.cpu(), predicted_labels.cpu(), average='weighted')\n",
    "\n",
    "print(f'Validation Accuracy: {accuracy}')\n",
    "print(f'Validation Precision: {precision}')\n",
    "print(f'Validation Recall: {recall}')\n",
    "print(f'Validation F1-Score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974e306e-7c62-478b-9b44-2db06b7d1310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics for each label\n",
    "metrics_data = []\n",
    "label_names = ['A1', 'A2', 'A3', 'B1', 'B2', 'B3', 'B4']\n",
    "\n",
    "for i, label_name in enumerate(label_names):\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels.cpu()[:, i], predicted_labels.cpu()[:, i], average='binary')\n",
    "    metrics_data.append([label_name, 'precision', precision])\n",
    "    metrics_data.append([label_name, 'recall', recall])\n",
    "    metrics_data.append([label_name, 'f1_score', f1])\n",
    "\n",
    "# Convert metrics data to DataFrame and save as CSV\n",
    "metrics_df = pd.DataFrame(metrics_data, columns=['Label', 'Metric', 'Value'])\n",
    "metrics_df.to_csv('label_metrics.csv', index=False)\n",
    "\n",
    "# Save the predictions in the desired format\n",
    "predictions_df = pd.DataFrame(predicted_labels.cpu().numpy(), columns=label_names)\n",
    "predictions_df.insert(0, 'Obs', val_texts)  # Insert the original observations back into the DataFrame\n",
    "predictions_df.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7c9de5-aa4a-453d-82d5-3e90b4a19cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = 'BERT/model_state_dict.pth'\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f'Model state dictionary saved to {model_save_path}')\n",
    "\n",
    "# Step 2 (Optional): Save the entire model\n",
    "full_model_save_path = 'BERT/full_model.pth'\n",
    "torch.save(model, full_model_save_path)\n",
    "print(f'Entire model saved to {full_model_save_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
